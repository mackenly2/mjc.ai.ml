{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNNfXa17ktae4Tn3V/VNEGj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bjungweapon/mjc.ai.ml/blob/BDU/BDU_HanBit_FullBatch_SGD_miniBatch_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NeMTCMYmbbQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# 1. ë°ì´í„° ìƒì„±\n",
        "X, y = make_regression(n_samples=1000, n_features=20, noise=10, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ----------------------\n",
        "# 1. Full-batch Gradient Descent (LinearRegression)\n",
        "# ----------------------\n",
        "model_full = LinearRegression()  # ë‚´ë¶€ì ìœ¼ë¡œ ì „ì²´ ë°ì´í„°ë¥¼ ì‚¬ìš©\n",
        "model_full.fit(X_train, y_train)\n",
        "y_pred_full = model_full.predict(X_test)\n",
        "mse_full = mean_squared_error(y_test, y_pred_full)\n",
        "\n",
        "# ----------------------\n",
        "# 2. Stochastic Gradient Descent (SGDRegressor, batch_size=1)\n",
        "# ----------------------\n",
        "model_sgd = SGDRegressor(learning_rate='constant', eta0=0.001, max_iter=1, tol=None, random_state=42)\n",
        "\n",
        "# ë°˜ë³µì ìœ¼ë¡œ í•œ ìƒ˜í”Œì”© í•™ìŠµ\n",
        "for epoch in range(100):\n",
        "    for i in range(len(X_train)):\n",
        "        model_sgd.partial_fit(X_train[i:i+1], y_train[i:i+1])\n",
        "\n",
        "y_pred_sgd = model_sgd.predict(X_test)\n",
        "mse_sgd = mean_squared_error(y_test, y_pred_sgd)\n",
        "\n",
        "# ----------------------\n",
        "# 3. Mini-batch Gradient Descent (SGDRegressor, batch_size=32)\n",
        "# ----------------------\n",
        "model_minibatch = SGDRegressor(learning_rate='constant', eta0=0.001, max_iter=1, tol=None, random_state=42)\n",
        "\n",
        "batch_size = 32\n",
        "n_batches = int(np.ceil(len(X_train) / batch_size))\n",
        "\n",
        "for epoch in range(100):\n",
        "    indices = np.random.permutation(len(X_train))\n",
        "    X_train_shuffled = X_train[indices]\n",
        "    y_train_shuffled = y_train[indices]\n",
        "    for i in range(n_batches):\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "        X_batch = X_train_shuffled[start:end]\n",
        "        y_batch = y_train_shuffled[start:end]\n",
        "        model_minibatch.partial_fit(X_batch, y_batch)\n",
        "\n",
        "y_pred_minibatch = model_minibatch.predict(X_test)\n",
        "mse_minibatch = mean_squared_error(y_test, y_pred_minibatch)\n",
        "\n",
        "# ----------------------\n",
        "# ê²°ê³¼ ë¹„êµ\n",
        "# ----------------------\n",
        "print(f\"Full-batch MSE     : {mse_full:.4f}\")\n",
        "print(f\"SGD MSE (batch=1)  : {mse_sgd:.4f}\")\n",
        "print(f\"Mini-batch MSE (32): {mse_minibatch:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Vf73fre-nLnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ì˜ˆì¸¡ vs ì‹¤ì œê°’ ì‹œê°í™” í•¨ìˆ˜\n",
        "def plot_predictions(y_test, preds, labels):\n",
        "    plt.figure(figsize=(18, 5))\n",
        "\n",
        "    for i, (y_pred, label) in enumerate(zip(preds, labels)):\n",
        "        plt.subplot(1, 3, i + 1)\n",
        "        plt.scatter(y_test, y_pred, alpha=0.5)\n",
        "        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # y=x ì„ \n",
        "        plt.xlabel(\"True Values\")\n",
        "        plt.ylabel(\"Predictions\")\n",
        "        plt.title(f\"{label} Prediction\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# ì‹œê°í™” ì‹¤í–‰\n",
        "plot_predictions(\n",
        "    y_test,\n",
        "    [y_pred_full, y_pred_sgd, y_pred_minibatch],\n",
        "    [\"Full-batch\", \"SGD (batch=1)\", \"Mini-batch (32)\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "pn5hsNHRnMMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"ì˜ˆì¸¡ ê²°ê³¼ë§Œ ë³´ë©´ ì„¸ ë°©ë²• ëª¨ë‘ í•™ìŠµì„ ì˜ í–ˆê¸° ë•Œë¬¸ì— ê·¸ë˜í”„ê°€ ë¹„ìŠ·í•˜ê²Œ ë‚˜ì˜µë‹ˆë‹¤.\n",
        "í•˜ì§€ë§Œ í•™ìŠµí•˜ëŠ” ê³¼ì •ì—ì„œì˜ ì°¨ì´ëŠ” ë¶„ëª…íˆ ì¡´ì¬í•˜ê³ , íŠ¹íˆ ë°ì´í„°ê°€ ì»¤ì§€ê±°ë‚˜ ëª¨ë¸ì´ ë³µì¡í•´ì§ˆìˆ˜ë¡\n",
        "'ì†ë„', 'ì•ˆì •ì„±', 'ìì› ì‚¬ìš©ëŸ‰'ì—ì„œ í° ì°¨ì´ë¥¼ ë³´ì´ê²Œ ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "elpMviogocUf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import time\n",
        "\n",
        "# 1. ë°ì´í„° ìƒì„±\n",
        "X, y = make_regression(n_samples=3000, n_features=20, noise=15, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# í•™ìŠµ íŒŒë¼ë¯¸í„°\n",
        "epochs = 50\n",
        "eta0 = 0.001\n",
        "\n",
        "def run_training(name, batch_size):\n",
        "    model = SGDRegressor(learning_rate='constant', eta0=eta0, max_iter=1, tol=None, random_state=42)\n",
        "    n = len(X_train)\n",
        "    losses = []\n",
        "    start = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        indices = np.random.permutation(n)\n",
        "        X_shuffled = X_train[indices]\n",
        "        y_shuffled = y_train[indices]\n",
        "        epoch_loss = 0\n",
        "        count = 0\n",
        "\n",
        "        for i in range(0, n, batch_size):\n",
        "            X_batch = X_shuffled[i:i + batch_size]\n",
        "            y_batch = y_shuffled[i:i + batch_size]\n",
        "            model.partial_fit(X_batch, y_batch)\n",
        "\n",
        "            # ì˜ˆì¸¡ ë° ì†ì‹¤ ê³„ì‚°\n",
        "            y_pred = model.predict(X_batch)\n",
        "            loss = mean_squared_error(y_batch, y_pred)\n",
        "            epoch_loss += loss\n",
        "            count += 1\n",
        "\n",
        "        losses.append(epoch_loss / count)\n",
        "\n",
        "    end = time.time()\n",
        "    total_time = end - start\n",
        "    return losses, total_time\n",
        "\n",
        "# Run Full-batch (batch_size = ì „ì²´ ë°ì´í„° ìˆ˜)\n",
        "loss_full, time_full = run_training(\"Full-batch\", batch_size=len(X_train))\n",
        "\n",
        "# Run SGD (batch_size = 1)\n",
        "loss_sgd, time_sgd = run_training(\"SGD\", batch_size=1)\n",
        "\n",
        "# Run Mini-batch (batch_size = 32)\n",
        "loss_mini, time_mini = run_training(\"Mini-batch\", batch_size=32)\n",
        "\n",
        "# -------------------------------\n",
        "# ğŸ“ˆ ê·¸ë˜í”„ 1: Loss vs Epoch\n",
        "# -------------------------------\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(loss_full, label=f\"Full-batch ({time_full:.2f}s)\")\n",
        "plt.plot(loss_sgd, label=f\"SGD (batch=1) ({time_sgd:.2f}s)\")\n",
        "plt.plot(loss_mini, label=f\"Mini-batch (batch=32) ({time_mini:.2f}s)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Mean Squared Error (Loss)\")\n",
        "plt.title(\"Loss vs Epoch (Training Stability & Speed)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# -------------------------------\n",
        "# ğŸ“‹ ê²°ê³¼ ì¶œë ¥\n",
        "# -------------------------------\n",
        "print(\"ì´ í•™ìŠµ ì‹œê°„:\")\n",
        "print(f\"Full-batch : {time_full:.2f}ì´ˆ\")\n",
        "print(f\"SGD        : {time_sgd:.2f}ì´ˆ\")\n",
        "print(f\"Mini-batch : {time_mini:.2f}ì´ˆ\")\n"
      ],
      "metadata": {
        "id": "ZzPJ-Skiodlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vbvKJpOyqx6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import time\n",
        "\n",
        "# 1. ë°ì´í„° ì¤€ë¹„\n",
        "X, y = make_regression(n_samples=2000, n_features=10, noise=20, random_state=0)\n",
        "X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# 2. í•™ìŠµ í•¨ìˆ˜\n",
        "def train_model(batch_size, eta0, epochs=50):\n",
        "    model = SGDRegressor(learning_rate='constant', eta0=eta0, max_iter=1, tol=None, random_state=0)\n",
        "    losses = []\n",
        "    n = len(X_train)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        indices = np.random.permutation(n)\n",
        "        X_shuffled = X_train[indices]\n",
        "        y_shuffled = y_train[indices]\n",
        "        epoch_loss = 0\n",
        "        count = 0\n",
        "\n",
        "        for i in range(0, n, batch_size):\n",
        "            X_batch = X_shuffled[i:i+batch_size]\n",
        "            y_batch = y_shuffled[i:i+batch_size]\n",
        "            model.partial_fit(X_batch, y_batch)\n",
        "            y_pred = model.predict(X_batch)\n",
        "            loss = mean_squared_error(y_batch, y_pred)\n",
        "            epoch_loss += loss\n",
        "            count += 1\n",
        "        losses.append(epoch_loss / count)\n",
        "    return losses\n",
        "\n",
        "# 3. ì‹¤í—˜ ì¡°í•©: (batch_size, eta0)\n",
        "configs = [\n",
        "    (1, 0.0001),   # ì‘ì€ ë°°ì¹˜ + ì‘ì€ í•™ìŠµë¥ \n",
        "    (1, 0.01),     # ì‘ì€ ë°°ì¹˜ + í° í•™ìŠµë¥ \n",
        "    (32, 0.001),   # ì¤‘ê°„ ë°°ì¹˜ + ì¤‘ê°„ í•™ìŠµë¥ \n",
        "    (len(X_train), 0.001),  # Full-batch + ì¤‘ê°„ í•™ìŠµë¥ \n",
        "    (len(X_train), 0.05),   # Full-batch + í° í•™ìŠµë¥ \n",
        "]\n",
        "\n",
        "# 4. í•™ìŠµ ë° ê·¸ë˜í”„ ì‹œê°í™”\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "for batch_size, eta0 in configs:\n",
        "    losses = train_model(batch_size, eta0)\n",
        "    label = f\"Batch={batch_size}, LR={eta0}\"\n",
        "    plt.plot(losses, label=label)\n",
        "\n",
        "plt.title(\"Loss vs Epoch (Learning Rate vs Batch Size)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss (MSE)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Rf5I5uNsqyW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì‹œê°í™” í•´ì„ ê°€ì´ë“œ\n",
        "ì§„ë™ì´ í° ê·¸ë˜í”„: ì‘ì€ ë°°ì¹˜, í° í•™ìŠµë¥ \n",
        "\n",
        "ëŠë¦¬ê²Œ ìˆ˜ë ´í•˜ëŠ” ê·¸ë˜í”„: ì‘ì€ í•™ìŠµë¥ \n",
        "\n",
        "ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ ìˆ˜ë ´: ì¤‘ê°„ ë°°ì¹˜ + ì ë‹¹í•œ í•™ìŠµë¥ \n",
        "\n",
        "Full-batchëŠ” ë§¤ìš° ë¶€ë“œëŸ¬ìš´ ìˆ˜ë ´, ê·¸ëŸ¬ë‚˜ ëŠë¦´ ìˆ˜ ìˆìŒ"
      ],
      "metadata": {
        "id": "tvvhzaR3reTU"
      }
    }
  ]
}